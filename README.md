This study based upon FELM benchmark, has covered the factuality evaluation performance of three LLMs for the segmented responses for various domains. The current study is conducted on the three LLMs to check the quality of content evaluation as well as measure the reliability. This project aims to address the absence of a standardized benchmark to access the factuality of LLM-generated content. It has been identified that this research is important to develop knowledge regarding content generation, text messages, and tables. It has been identified that the lack of a standardized framework as well as assessment blocks and limitations of LLMs have impacted the content outcomes. It can be said that models including CoT & RAT are important to increase the accuracy as well as precision beyond the Vanilla/Raw prompting.
